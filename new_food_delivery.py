# -*- coding: utf-8 -*-
"""New_food_delivery.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1YW0WM4ew5emBDR0ZagHSj2xJDblnk-A4
"""

import numpy as np
import pandas as pd

df = pd.read_csv("train.csv")

df.shape

df.head()

df.info()

df.isnull().sum()

# Remove '(min)' text and convert to integer
df['Time_taken(min)'] = df['Time_taken(min)'].str.replace('(min)', '', regex=False)
df['Time_taken(min)'] = df['Time_taken(min)'].str.strip().astype(int)

df['Time_taken(min)'].head()

# List of categorical columns to clean
cat_cols = ['Weatherconditions', 'Road_traffic_density',
            'Type_of_order', 'Type_of_vehicle', 'Festival', 'City']

for col in cat_cols:
    df[col] = df[col].astype(str).str.strip().str.lower()

# remove prefix "conditions " from weather column
df['Weatherconditions'] = df['Weatherconditions'].str.replace('conditions ', '')

print(df.dtypes)

# Convert Order_Date to datetime (day-month-year)
df['Order_Date'] = pd.to_datetime(df['Order_Date'], format='%d-%m-%Y', errors='coerce')

# Convert Time columns (hour:minute:second)
df['Time_Orderd'] = pd.to_datetime(df['Time_Orderd'], format='%H:%M:%S', errors='coerce').dt.time
df['Time_Order_picked'] = pd.to_datetime(df['Time_Order_picked'], format='%H:%M:%S', errors='coerce').dt.time

# Check the first few rows
df[['Order_Date', 'Time_Orderd', 'Time_Order_picked']].head()

# Replace "NaN ", "NaN", "--" with np.nan
df.replace(["NaN ", "NaN", "nan", "--", "null", ""], np.nan, inplace=True)

print(df.isnull().sum())

#Drop rows with missing values
df = df.dropna()

print(df.shape)

# Convert Age & Ratings columns to numeric (force errors to NaN)
df['Delivery_person_Age'] = pd.to_numeric(df['Delivery_person_Age'], errors='coerce')
df['Delivery_person_Ratings'] = pd.to_numeric(df['Delivery_person_Ratings'], errors='coerce')

print(df[['Delivery_person_Age','Delivery_person_Ratings']].describe())

# Drop unrealistic ages (keep only between 18 and 65)
df = df[(df['Delivery_person_Age'] >= 18) & (df['Delivery_person_Age'] <= 65)]

# Cap ratings between 1 and 5
df = df[(df['Delivery_person_Ratings'] >= 1) & (df['Delivery_person_Ratings'] <= 5)]

print(df.shape)

df.info()

df.head()

# Save cleaned dataset
df.to_csv("cleaned_food_delivery.csv", index=False)

"""#Calculate Distance"""

# Haversine formula to calculate distance between two coordinates
def haversine_distance(lat1, lon1, lat2, lon2):
    R = 6371  # Earth radius in kilometers
    lat1, lon1, lat2, lon2 = map(np.radians, [lat1, lon1, lat2, lon2])
    dlat = lat2 - lat1
    dlon = lon2 - lon1

    a = np.sin(dlat/2)**2 + np.cos(lat1)*np.cos(lat2)*np.sin(dlon/2)**2
    c = 2 * np.arcsin(np.sqrt(a))
    return R * c

# Apply formula to dataset
df['Distance_km'] = haversine_distance(
    df['Restaurant_latitude'], df['Restaurant_longitude'],
    df['Delivery_location_latitude'], df['Delivery_location_longitude']
)

# Check results
print(df[['Restaurant_latitude','Restaurant_longitude',
          'Delivery_location_latitude','Delivery_location_longitude','Distance_km']].head())

"""#Order to pickup duration"""

# First, convert times properly to datetime.time if not already done
df['Time_Orderd'] = pd.to_datetime(df['Time_Orderd'], format='%H:%M:%S', errors='coerce')
df['Time_Order_picked'] = pd.to_datetime(df['Time_Order_picked'], format='%H:%M:%S', errors='coerce')

# Calculate difference (in seconds → then convert to minutes)
df['Order_to_pickup_min'] = (df['Time_Order_picked'] - df['Time_Orderd']).dt.total_seconds() / 60

# Some values may be negative or NaN if times are missing → handle them
df['Order_to_pickup_min'] = df['Order_to_pickup_min'].fillna(0)   # replace NaN with 0
df.loc[df['Order_to_pickup_min'] < 0, 'Order_to_pickup_min'] = 0  # fix negative values

# Check results
print(df[['Time_Orderd','Time_Order_picked','Order_to_pickup_min']].head())

"""#Extract Date & Time feature"""

# Make sure Order_Date is datetime type
df['Order_Date'] = pd.to_datetime(df['Order_Date'], errors='coerce')

# Extract features from Order_Date
df['day'] = df['Order_Date'].dt.day
df['month'] = df['Order_Date'].dt.month
df['weekday'] = df['Order_Date'].dt.weekday  # Monday=0, Sunday=6
df['is_weekend'] = df['weekday'].apply(lambda x: 1 if x >= 5 else 0)

# Extract features from Order time
df['hour'] = df['Time_Orderd'].dt.hour

# Define peak hours (lunch 11–14, dinner 18–21)
df['peak_hour'] = df['hour'].apply(lambda h: 1 if (11 <= h <= 14) or (18 <= h <= 21) else 0)

# Check results
print(df[['Order_Date','Time_Orderd','day','month','weekday','is_weekend','hour','peak_hour']].head())

df.info()

# Step 1: drop raw redundant columns
cols_to_drop = [
    'Restaurant_latitude','Restaurant_longitude',
    'Delivery_location_latitude','Delivery_location_longitude',
    'Order_Date','Time_Orderd','Time_Order_picked', 'ID', 'Delivery_person_ID'
]
df = df.drop(columns=[c for c in cols_to_drop if c in df.columns], errors='ignore')
df.shape

df.info()

"""#checks & fix data types / missing values"""

# Ensure target numeric
df['Time_taken(min)'] = df['Time_taken(min)'].astype(str).str.replace(r'[^0-9.-]', '', regex=True)
df['Time_taken(min)'] = pd.to_numeric(df['Time_taken(min)'], errors='coerce')

# multiple_deliveries numeric; if missing assume 1 (or choose median)
df['multiple_deliveries'] = pd.to_numeric(df.get('multiple_deliveries', np.nan), errors='coerce')
df['multiple_deliveries'] = df['multiple_deliveries'].fillna(1).astype(int)

# Quick missing-value report
missing = df.isnull().sum().sort_values(ascending=False)
print(missing[missing>0])

# Example imputation policy for numeric columns with a few nulls:
num_cols = ['Delivery_person_Age','Delivery_person_Ratings','Distance_km','Order_to_pickup_min']
for c in num_cols:
    if c in df.columns:
        df[c] = pd.to_numeric(df[c], errors='coerce')
        df[c] = df[c].fillna(df[c].median())

# Verify no nulls left in features/target you will use
print("Nulls after imputation:")
print(df[num_cols + ['Time_taken(min)']].isnull().sum())

df.info()

"""#Define numeric & categorical feature lists"""

numeric_features = [
    'Delivery_person_Age',
    'Delivery_person_Ratings',
    'Distance_km',
    'Order_to_pickup_min',
    'multiple_deliveries'
]

categorical_features = [
    'Weatherconditions',
    'Road_traffic_density',
    'Type_of_order',
    'Type_of_vehicle',
    'Festival',
    'City'
]

# sanity: keep only features that exist
numeric_features = [c for c in numeric_features if c in df.columns]
categorical_features = [c for c in categorical_features if c in df.columns]

print("Numeric:", numeric_features)
print("Categorical:", categorical_features)

"""#train/test split"""

from sklearn.model_selection import train_test_split

X = df[numeric_features + categorical_features].copy()
y = df['Time_taken(min)'].copy()


X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.20, random_state=42
)

print("Train:", X_train.shape, "Test:", X_test.shape)

"""#Build ColumnTransformer + Pipeline + Models (StandardScaler + OneHotEncoder + RF)"""

from sklearn.tree import DecisionTreeRegressor
from sklearn.linear_model import LinearRegression
from sklearn.ensemble import RandomForestRegressor
from sklearn.pipeline import Pipeline
from sklearn.compose import ColumnTransformer
from sklearn.preprocessing import StandardScaler, OneHotEncoder
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score


preprocessor = ColumnTransformer(
    transformers=[
        ('num', StandardScaler(), numeric_features),
        ('cat', OneHotEncoder(handle_unknown='ignore', sparse_output=False), categorical_features)
    ],
    remainder='drop'  # drop any other columns
)


dt_pipeline = Pipeline([("preprocessor", preprocessor), ("model", DecisionTreeRegressor(random_state=42))])
lr_pipeline = Pipeline([("preprocessor", preprocessor), ("model", LinearRegression())])
rf_pipeline = Pipeline([("preprocessor", preprocessor), ("model", RandomForestRegressor(random_state=42))])

# Fit (note: preprocessor will refit inside each pipeline)
dt_pipeline.fit(X_train, y_train)
lr_pipeline.fit(X_train, y_train)
rf_pipeline.fit(X_train, y_train)

y_pred_dt = dt_pipeline.predict(X_test)
y_pred_lr = lr_pipeline.predict(X_test)
y_pred_rf = rf_pipeline.predict(X_test)

# metrics
def metrics(y_true, y_pred):
    return {
        "MAE": mean_absolute_error(y_true, y_pred),
        "RMSE": np.sqrt(mean_squared_error(y_true, y_pred)),
        "R2": r2_score(y_true, y_pred)
    }

results = {
    "RandomForest": metrics(y_test, y_pred_rf),
    "DecisionTree": metrics(y_test, y_pred_dt),
    "LinearRegression": metrics(y_test, y_pred_lr)
}

results_df = pd.DataFrame(results).T.reset_index().rename(columns={"index":"model"})
print(results_df)

# RandomForest
rf_model = RandomForestRegressor(
    n_estimators=100,
    max_depth=15,
    min_samples_split=10,
    min_samples_leaf=5,
    random_state=42,
    n_jobs=-1
)

# Pipeline
pipeline = Pipeline([
    ('preprocessor', preprocessor),
    ('model', rf_model)
])

pipeline.fit(X_train, y_train)

"""#Feature importance"""

# get numeric names
num_names = numeric_features

# get categorical one-hot names (after fitting)
ohe = pipeline.named_steps['preprocessor'].named_transformers_['cat']
cat_names = list(ohe.get_feature_names_out(categorical_features))

feature_names = num_names + cat_names

import pandas as pd
import matplotlib.pyplot as plt

importances = pipeline.named_steps['model'].feature_importances_
fi = pd.DataFrame({'feature': feature_names, 'importance': importances}).sort_values('importance', ascending=False)

# show top 15
print(fi.head(15))

# plot
plt.figure(figsize=(8,6))
plt.barh(fi['feature'].head(15)[::-1], fi['importance'].head(15)[::-1])
plt.title("Top 15 feature importances")
plt.xlabel("Importance")
plt.show()

import matplotlib.pyplot as plt

# 2) Actual vs Predicted scatter
plt.figure(figsize=(6,6))
plt.scatter(y_test, y_pred_rf, alpha=0.4)
minv = min(y_test.min(), y_pred_rf.min())
maxv = max(y_test.max(), y_pred_rf.max())
plt.plot([minv, maxv], [minv, maxv], linestyle="--", color="red", linewidth=2)
plt.xlabel("Actual Delivery Time")
plt.ylabel("Predicted Delivery Time")
plt.title("Actual vs Predicted")
plt.tight_layout()
plt.show()

# 3) Residual histogram
residuals = y_test - y_pred_rf
plt.figure(figsize=(7,4))
plt.hist(residuals, bins=30)
plt.xlabel("Residual (Actual - Predicted)")
plt.title("Residuals Distribution")
plt.tight_layout()
plt.show()

"""#test for Distance_km"""

# choose a baseline input from X_test (first row)
base = X_test.iloc[0].copy()
distances = [0.5, 1, 2, 5, 10, 20, 50]

print("Distance -> Predicted time (min)")
for d in distances:
    base['Distance_km'] = d
    pred = pipeline.predict(pd.DataFrame([base]))[0]
    print(f"{d} km -> {pred:.2f}")

print("Distance range train:", X_train['Distance_km'].min(), X_train['Distance_km'].max())

# Remove extreme outliers
df = df[df['Distance_km'] <= 50]   # keep only realistic deliveries

print("Distance range after cleaning:", df['Distance_km'].min(), df['Distance_km'].max())

df = df[(df['Delivery_person_Age'] >= 18) & (df['Delivery_person_Age'] <= 65)]
df = df[(df['Delivery_person_Ratings'] >= 1) & (df['Delivery_person_Ratings'] <= 5)]
df = df[df['Order_to_pickup_min'] <= 60]
df = df[df['Time_taken(min)'] <= 120]

import joblib
joblib.dump(pipeline, "rf_pipeline.pkl")
print("Saved rf_pipeline.pkl")

import pandas as pd

# Combine features and target into one DataFrame
final_df = X.copy()
final_df['Time_taken(min)'] = y   # target column

# Save to CSV
final_df.to_csv("food_delivery_preprocessed.csv", index=False)

# Download
from google.colab import files
files.download("food_delivery_preprocessed.csv")